{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01e3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "from dolfinx import log\n",
    "from dolfinx.io import XDMFFile\n",
    "from  useful_functions import *\n",
    "\n",
    "from dolfinx.io.gmshio import read_from_msh\n",
    "\n",
    "#log.set_log_level(log.LogLevel.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9daf58",
   "metadata": {},
   "source": [
    "# IMPORTING THE MESH #\n",
    "Vado ad importare la mesh da un file .xdfm oppure da un file .msh\n",
    "(dovrebbe essere praticamente la stessa cosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1e27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info    : Reading '../mesh_files/michele_mesh/Mesh.msh'...\n",
      "Info    : 11733 nodes\n",
      "Info    : 23466 elements\n",
      "Info    : Done reading '../mesh_files/michele_mesh/Mesh.msh'\n"
     ]
    }
   ],
   "source": [
    "from  useful_functions import *\n",
    "\n",
    "# Potrei leggere la mesh da un file.xdmf, nel seguente modo:\n",
    "# path_xdmf= \"../mesh_files/gianlu_mesh/gian_mesh.xdmf\"\n",
    "# with XDMFFile(MPI.COMM_WORLD, \"../mesh_files/gianlu_mesh/gian_mesh.xdmf\", \"r\") as xdmf:\n",
    "#     domain = xdmf.read_mesh(name='mesh')\n",
    "#    ct = xdmf.read_meshtags(domain,name='mesh')  #cosa fare con questa riga??\n",
    "\n",
    "\n",
    "# Oppure potrei leggere la mesh (ed altre info utili) da un file.msh \n",
    "path_msh=\"../mesh_files/michele_mesh/Mesh.msh\"\n",
    "domain, cell_tags, facet_tags=read_from_msh(path_msh,MPI.COMM_WORLD,gdim=2)  \n",
    "\n",
    "\n",
    "L, H, c_x, c_y, r= L_H_cx_cy_r(domain, facet_tags) #individuo dimensioni del dominio \n",
    "# plt_mesh(domain,save_as_png=True) #Plotto o salvo in un png la mesh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782f8567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:  10.0\n",
      "L:  27.0\n",
      "\n",
      "Centro ostacolo: (9.0, 5.0)\n",
      "Raggio: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('H: ',H)\n",
    "print('L: ',L)\n",
    "print('')\n",
    "print(f\"Centro ostacolo: ({c_x:.1f}, {c_y:.1f})\")\n",
    "print(f'Raggio: {r:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a82c8d",
   "metadata": {},
   "source": [
    "# DEFINING THE VECTOR SPACES\n",
    "#definisco spazi vettoriali di velocità e pressione (Seguendo la legge di Taylor-Hood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0cf6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from basix.ufl import element\n",
    "from dolfinx import fem\n",
    "v_cg2=element(\"Lagrange\", domain.topology.cell_name(), 2, shape=(domain.geometry.dim,)) # u sarà quadratica \n",
    "s_cg1 = element(\"Lagrange\", domain.topology.cell_name(), 1) # p sarà lineare\n",
    "V = fem.functionspace(domain, v_cg2)\n",
    "Q = fem.functionspace(domain, s_cg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df708af",
   "metadata": {},
   "source": [
    "# DEFINING THE BOUNDARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63e9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufl import SpatialCoordinate\n",
    "x = SpatialCoordinate(domain)\n",
    "\n",
    "boundaries = [(1, lambda x: np.isclose(x[0], 0)), # inflow\n",
    "              (2, lambda x: np.isclose(x[0], L)), # outflow\n",
    "              (3, lambda x: np.isclose(x[1], 0)), # bottom boundary\n",
    "              (4, lambda x: np.isclose(x[1], H)), # top boundary \n",
    "              (5, lambda x: np.isclose(np.sqrt((x[0] - c_x)**2 + (x[1] - c_y)**2),r))] # disk boundary \n",
    "\n",
    "# boundaries è quindi una lista di tuple \n",
    "# lambda x: np.isclose(....) saranno i \"locator\" \n",
    "# 1,2,3,4,5 saranno i \"marker\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392c7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dolfinx.mesh import locate_entities, meshtags\n",
    "\n",
    "facet_indices, facet_markers = [], []\n",
    "fdim = domain.topology.dim - 1\n",
    "for (marker, locator) in boundaries:\n",
    "    facets = locate_entities(domain, fdim, locator) # individuo gli indici delle entities (facets) appartenenti ad un particolare boundary \n",
    "    facet_indices.append(facets) # aggiungo gli indici appena trovati a \"facet_indices\"\n",
    "    facet_markers.append(np.full_like(facets, marker)) # appendo a facet_marker un array delle stesse dimensioni di quello che conteneva gli \n",
    "    # indici appena trovati (ovvero facets) \n",
    "    # ma con tutti gli elementi al suo interno uguali al \"marker\" di riferimento!!! (Quindi, ad esempio, un array di tutti 1)\n",
    "\n",
    "facet_indices = np.hstack(facet_indices).astype(np.int32)\n",
    "facet_markers = np.hstack(facet_markers).astype(np.int32)\n",
    "\n",
    "sorted_facets = np.argsort(facet_indices) # It returns an array of indices of the same shape as 'facet_indices' that contiene gli indici \n",
    "# degli elementi di 'facet_indices' ordinati in maniera crescente \n",
    "# Ad esempio, se: facet_indices = np.array([3, 1, 2]) allora: np.argsort(facet_indices) = array([1, 2, 0])\n",
    "\n",
    "\n",
    "facet_tag = meshtags(domain, fdim, facet_indices[sorted_facets], facet_markers[sorted_facets]) # Create a MeshTags object \n",
    "# facet_indices[sorted_facets] e facet_markers[sorted_facets] saranno 2 array contenenti rispettivamente gli indici degli entities \n",
    "# appartenenti ai boundaries (ordinati in maniera crescente)\n",
    "# ed i rispettivi markers identificativi(1,2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c15db30",
   "metadata": {},
   "source": [
    "Vado a verificare le BC con Paraview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f57b7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain.topology.create_connectivity(domain.topology.dim-1, domain.topology.dim)\n",
    "with XDMFFile(domain.comm, \"facet_tags_V2.xdmf\", \"w\") as xdmf:\n",
    "    xdmf.write_mesh(domain)\n",
    "    xdmf.write_meshtags(facet_tag, domain.geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9b7e6",
   "metadata": {},
   "source": [
    "# DEFINING BC AND VARIATIONAL PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb322f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufl import  TestFunction, TrialFunction\n",
    "\n",
    "# Define trial and test functions\n",
    "u = TrialFunction(V)\n",
    "v = TestFunction(V)\n",
    "\n",
    "p = TrialFunction(Q)\n",
    "q = TestFunction(Q)\n",
    "\n",
    "from dolfinx.fem import Function\n",
    "# Create useful functions\n",
    "u0 = Function(V) # ha valore 0 su tutto il dominio (serve per inizializzare u allo step zero)\n",
    "u1 = Function(V)\n",
    "\n",
    "p0=Function(Q)\n",
    "p1 = Function(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ad3a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definisco le funzioni che mi serviranno durante il calcolo di mean flow e forzaggio \n",
    "u_mean_old = Function(V)\n",
    "u_mean = Function(V)\n",
    "u_fluct = Function(V)\n",
    "\n",
    "f_old = Function(V)\n",
    "f= Function(V)\n",
    "f_save = Function(V)\n",
    "\n",
    "p_mean = Function(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1022951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from petsc4py import PETSc\n",
    "\n",
    "#Defining the constant of the problem \n",
    "Re=60 # oppure provare Re=150?\n",
    "nu=1/Re \n",
    "dt=0.01\n",
    "\n",
    "t=0 # = dt ??\n",
    "num_steps=600  # 10000\n",
    "step_init = 10000\n",
    "step = 1\n",
    "step_final = 1000000\n",
    "# t=0.01\n",
    "# T=...\n",
    "# n_steps= ...\n",
    "\n",
    "k=fem.Constant(domain,PETSc.ScalarType(dt)) # time-step \n",
    "f_zero= fem.Constant(domain, PETSc.ScalarType((0, 0))) # this should be used only at the very first step!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7c07c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufl import FacetNormal,dot, grad, inner \n",
    "\n",
    "n = FacetNormal(domain)\n",
    "# g_u = -(nu*dot(n, grad(u)) - p1*n)\n",
    "# g_u = -nu* dot(n, grad(u))\n",
    "\n",
    "g_p= p*n[0]\n",
    "# g_p= p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7efdde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ufl import Measure\n",
    "ds = Measure(\"ds\", domain=domain, subdomain_data=facet_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b03838",
   "metadata": {},
   "source": [
    "Creo una classe che mi aiuterà a definire le BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7749a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dolfinx.fem import Function, dirichletbc, locate_dofs_topological\n",
    "from ufl import div, dx, inner, lhs, rhs\n",
    "from dolfinx import default_scalar_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ebc5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdim=2\n",
    "#Defining BC \n",
    "class InletVelocity():\n",
    "    def __init__(self, t):\n",
    "        self.t = t\n",
    "    def __call__(self, x):\n",
    "        values = np.zeros((gdim, x.shape[1]), dtype=PETSc.ScalarType)\n",
    "        values[0] = 4 * 1.5 * np.sin(self.t * np.pi / 8) * x[1] * (0.41 - x[1]) / (0.41**2)\n",
    "        return values\n",
    "    \n",
    "u_inlet_free_slip = Function(V)\n",
    "inlet_velocity = InletVelocity(t)\n",
    "u_inlet_free_slip.interpolate(inlet_velocity)\n",
    "bcu_inflow = dirichletbc(u_inlet_free_slip, locate_dofs_topological(V, fdim, facet_tag.find(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cf7b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundaryCondition():\n",
    "    def __init__(self, type, marker, values):\n",
    "        self._type = type\n",
    "        if type == \"Dirichlet\":\n",
    "            facets = facet_tag.find(marker)\n",
    "            dofs = locate_dofs_topological(V, fdim, facets)\n",
    "            self._bc = dirichletbc(values, dofs, V)\n",
    "        elif type == \"Dirichlet_u_y\":\n",
    "            facets = facet_tag.find(marker)\n",
    "            dofs = locate_dofs_topological(V, fdim, facets)\n",
    "            self._bc = dirichletbc(values, dofs, V.sub(1))\n",
    "        elif type == \"Dirichlet_p\":\n",
    "            facets = facet_tag.find(marker)\n",
    "            dofs = locate_dofs_topological(Q, fdim, facets)\n",
    "            self._bc = dirichletbc(values, dofs, Q)\n",
    "        elif type == \"Neumann\":\n",
    "                self._bc = inner(values, v) * ds(marker)\n",
    "        elif type == \"Neumann_p\":\n",
    "                self._bc = values * q * ds(marker)\n",
    "        else:\n",
    "            raise TypeError(\"Unknown boundary condition: {0:s}\".format(type))\n",
    "    @property\n",
    "    def bc(self):\n",
    "        return self._bc\n",
    "    @property\n",
    "    def type(self):\n",
    "        return self._type\n",
    "\n",
    "#Dirichelet values \n",
    "u_inlet=PETSc.ScalarType((1,0)) \n",
    "u_y_top_bottom=PETSc.ScalarType(0) \n",
    "u_disk=PETSc.ScalarType((0,0))\n",
    "u_no_slip=PETSc.ScalarType((0,0))\n",
    "p_in=PETSc.ScalarType(8) \n",
    "p_out=PETSc.ScalarType(0) \n",
    "\n",
    "#Define the BC for step 1\n",
    "boundary_conditions_step1 = [BoundaryCondition(\"Dirichlet\", 3, u_no_slip), \n",
    "                            BoundaryCondition(\"Dirichlet\", 4, u_no_slip), \n",
    "                            BoundaryCondition(\"Dirichlet\", 5, u_no_slip)]\n",
    "\n",
    "\n",
    "#Define the BC for step 2\n",
    "# boundary_conditions_step2 = [BoundaryCondition(\"Neumann_p\", 2, g_p)]\n",
    "\n",
    "boundary_conditions_step2 = [BoundaryCondition(\"Dirichlet_p\", 1, p_in),\n",
    "                             BoundaryCondition(\"Dirichlet_p\", 2, p_out)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa90e18",
   "metadata": {},
   "source": [
    "Let's define the 3 Linear problems!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b4c6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "#calculation of the tentative velocity u* (by using p(n-1) and u(n-1))\n",
    "from ufl import inner, nabla_grad, dot, grad, ds, dx, lhs, rhs, div \n",
    "F1=(1/k)*inner(u-u0,v)*dx \n",
    "# F1+=inner(dot(u0,nabla_grad(u0)),v)*dx \n",
    "F1+=inner(grad(u0)*u0,v)*dx\n",
    "F1+=nu*inner(grad(u),grad(v))*dx\n",
    "F1-=inner(f_zero,v)*dx\n",
    "\n",
    "bcu_1, bcp_1 = [],[]\n",
    "for condition in boundary_conditions_step1:\n",
    "    if condition.type == \"Dirichlet\" or condition.type == \"Dirichlet_u_y\":\n",
    "        bcu_1.append(condition.bc)\n",
    "    elif condition.type == \"Dirichlet_p\":\n",
    "        bcp_1.append(condition.bc)\n",
    "    else:\n",
    "        F1 += condition.bc\n",
    "\n",
    "############\n",
    "bcu_1.append(bcu_inflow)\n",
    "##############\n",
    "from dolfinx.fem import form \n",
    "#definisco quindi la classica forma: a(u,v)=L(v)\n",
    "a1=form(lhs(F1))\n",
    "L1=form(rhs(F1))\n",
    "\n",
    "from dolfinx.fem.petsc import assemble_matrix, assemble_vector, apply_lifting, create_vector, set_bc\n",
    "A1 = assemble_matrix(a1, bcs=bcu_1)\n",
    "A1.assemble()\n",
    "b1 = create_vector(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b7d2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2 \n",
    "#caluclation of the new pressure (p_n) (by using u*)\n",
    "a2=inner(grad(p),grad(q))*dx \n",
    "\n",
    "bcu_2, bcp_2 = [],[]\n",
    "for condition in boundary_conditions_step2:\n",
    "    if condition.type == \"Dirichlet\" or condition.type == \"Dirichlet_u_y\":\n",
    "        bcu_2.append(condition.bc)\n",
    "    elif condition.type == \"Dirichlet_p\":\n",
    "        bcp_2.append(condition.bc)\n",
    "    else:\n",
    "        a2 += condition.bc\n",
    "\n",
    "a2=form(a2)\n",
    "\n",
    "L2=-(1/k)*div(u1)*q*dx #non si usa inner o dot (poiché sia div(u1) che q sono degli scalari!)\n",
    "L2=form(L2)\n",
    "\n",
    "A2 = assemble_matrix(a2, bcs=bcp_2)\n",
    "A2.assemble()\n",
    "b2 = create_vector(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a81cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3 \n",
    "#calculation of the new velocity (u_n) (by using u* and p_n)\n",
    "a3=inner(u,v)*dx\n",
    "a3=form(a3)\n",
    "L3=inner(u1,v)*dx - k*inner(grad(p1),v)*dx\n",
    "L3=form(L3)\n",
    "\n",
    "A3= assemble_matrix(a3, bcs=bcu_1) \n",
    "# Ad A3 (e neanche a b3) non c'é bisogno di applicare le BC poiché queste erano già state applicate nei primi 2 step \n",
    "# quindi, implicitamente verranno rispettate anche dal risultato dello step 3  \n",
    "A3.assemble()\n",
    "b3= create_vector(L3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ae2996",
   "metadata": {},
   "source": [
    "Adesso che quindi abbiamo definito tutte le strutture necessarie per i problemi lineare possiamo creare quindi i vari \n",
    "solver utilizzando PETSc (possiamo anche customizzare la strategia di risoluzione pre ogni problema)\n",
    "\n",
    "For the tentative velocity step and pressure correction step, we will use the Stabilized version of BiConjugate Gradient to solve the linear system, and using algebraic multigrid for preconditioning. \n",
    "\n",
    "For the last step, the velocity update, we use a conjugate gradient method with successive over relaxation, Gauss Seidel (SOR) preconditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33803538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solver for step 1\n",
    "solver1 = PETSc.KSP().create(domain.comm)\n",
    "solver1.setOperators(A1)\n",
    "solver1.setType(PETSc.KSP.Type.BCGS)\n",
    "pc1 = solver1.getPC()\n",
    "pc1.setType(PETSc.PC.Type.HYPRE)\n",
    "pc1.setHYPREType(\"boomeramg\")\n",
    "\n",
    "# Solver for step 2\n",
    "solver2 = PETSc.KSP().create(domain.comm)\n",
    "solver2.setOperators(A2)\n",
    "solver2.setType(PETSc.KSP.Type.BCGS)\n",
    "pc2 = solver2.getPC()\n",
    "pc2.setType(PETSc.PC.Type.HYPRE)\n",
    "pc2.setHYPREType(\"boomeramg\")\n",
    "\n",
    "# Solver for step 3\n",
    "solver3 = PETSc.KSP().create(domain.comm)\n",
    "solver3.setOperators(A3)\n",
    "solver3.setType(PETSc.KSP.Type.CG)\n",
    "pc3 = solver3.getPC()\n",
    "pc3.setType(PETSc.PC.Type.SOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b616cd",
   "metadata": {},
   "source": [
    "# SOLVING THE VARIATIONAL PROBLEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1227b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3706c192c3448afb6a769a2d7a33e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving PDE:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dolfinx.io import VTXWriter\n",
    "from tqdm.notebook import tqdm\n",
    "#from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "folder = Path(\"results_V2\")\n",
    "folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "vtx_u = VTXWriter(domain.comm, folder/\"flow_u.bp\", [u0], engine=\"BP4\") \n",
    "vtx_p = VTXWriter(domain.comm, folder/\"pressure_p.bp\", [p1], engine=\"BP4\") \n",
    "\n",
    "#associo il tempo t \n",
    "vtx_u.write(t)\n",
    "vtx_p.write(t)\n",
    "\n",
    "#progress = tqdm.autonotebook.tqdm(desc=\"Solving PDE\", total=num_steps)\n",
    "progress = tqdm(desc=\"Solving PDE\", total=num_steps)    #serve solo per visualizzare il progresso (in %) della solzuione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4562e1d",
   "metadata": {},
   "source": [
    "Quando scrivi un file .bp con engine=\"BP4\" (come in VTXWriter), non viene creato un singolo file leggibile come testo, \n",
    "\n",
    "ma un container binario suddiviso in più file \"fisici\". \n",
    "\n",
    "Questo è normale e previsto dal funzionamento interno di ADIOS2.\n",
    "\n",
    "Quindi, ad esempio, all’interno della directory \"poiseuille_u.bp\", troverò:\n",
    "\n",
    "-data.0    <---Contiene i dati numerici binari grezzi (cioè valori dei campi FEM, vettori, ecc.).\n",
    "\n",
    "-md.0    <---Contiene i metadati (descrizione del contenuto, nomi delle variabili, topologia).\n",
    "\n",
    "-md.idx  <---È un indice rapido dei metadati, usato per l’accesso efficiente e la parallelizzazione.\n",
    "\n",
    "Tutti insieme, questi 3 file compongono il file .bp, e devono essere trattati come un tutt'uno.\n",
    "\n",
    "\n",
    "\n",
    "In ParaView, puoi aprire direttamente poiseuille_u.bp e ParaView si occuperà di interpretare correttamente data.0, md.0, e md.idx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a875c939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 50\n",
      "u50 =  [ 1.49287784e-01 -3.22049297e-06  1.49301133e-01 ...  1.50640331e-03\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "p50 =  [0.         0.         0.06406442 ... 7.86919587 7.99998699 7.99998699]\n",
      "\n",
      "STEP 51\n",
      "u51 =  [ 1.52200239e-01 -3.35181437e-06  1.52214070e-01 ...  1.54320252e-03\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "p51 =  [0.         0.         0.06405254 ... 7.8673387  7.99998699 7.99998699]\n",
      "\n",
      "STEP 52\n",
      "u52 =  [ 1.55112126e-01 -3.48560345e-06  1.55126444e-01 ...  1.58003645e-03\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "p52 =  [0.         0.         0.06404062 ... 7.86546709 7.99998698 7.99998698]\n",
      "\n",
      "STEP 53\n",
      "u53 =  [ 1.58023445e-01 -3.62184757e-06  1.58038255e-01 ...  1.61689782e-03\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "p53 =  [0.         0.         0.06402866 ... 7.86358095 7.99998698 7.99998698]\n",
      "\n",
      "STEP 54\n",
      "u54 =  [ 1.60934193e-01 -3.76053371e-06  1.60949501e-01 ...  1.65377940e-03\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "p54 =  [0.         0.         0.06401666 ... 7.86168019 7.99998698 7.99998698]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<petsc4py.PETSc.KSP at 0x15d4c27a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dolfinx.fem import apply_lifting\n",
    "from dolfinx.fem.petsc import LinearProblem\n",
    "\n",
    "for i in range(num_steps):  #al posto di num_steps (in realtà dovrebbe esserci step_final!!!!!!)\n",
    "    progress.update(1)\n",
    "    # Update current time step\n",
    "    t += dt\n",
    "\n",
    "\n",
    "    # Step 1: Tentative velocity step\n",
    "    with b1.localForm() as loc_1:\n",
    "        loc_1.set(0)\n",
    "    assemble_vector(b1, L1)\n",
    "    apply_lifting(b1, [a1], [bcu_1])\n",
    "    b1.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE)\n",
    "    set_bc(b1, bcu_1)\n",
    "    solver1.solve(b1, u1.x.petsc_vec)\n",
    "    u1.x.scatter_forward()\n",
    "\n",
    "    # Step 2: Pressure corrrection step\n",
    "    with b2.localForm() as loc_2:\n",
    "        loc_2.set(0)\n",
    "    assemble_vector(b2, L2)\n",
    "    apply_lifting(b2, [a2], [bcp_2])\n",
    "    b2.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE)\n",
    "    set_bc(b2, bcp_2)\n",
    "    solver2.solve(b2, p1.x.petsc_vec)\n",
    "    p1.x.scatter_forward()\n",
    "\n",
    "    # Step 3: Velocity correction step\n",
    "    with b3.localForm() as loc_3:\n",
    "        loc_3.set(0)\n",
    "    assemble_vector(b3, L3)\n",
    "    apply_lifting(b3, [a3], [bcu_1])\n",
    "    b3.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE)\n",
    "    set_bc(b3, bcu_1)\n",
    "    solver3.solve(b3, u1.x.petsc_vec)\n",
    "    u1.x.scatter_forward()\n",
    "\n",
    "    if i > step_init:\n",
    "        actual_step=i-step_init\n",
    "        \n",
    "        u_mean.x.array[:]=(actual_step/(actual_step+1))*u_mean.x.array[:] + 1/(actual_step+1)*u1.x.array[:]\n",
    "        p_mean.x.array[:]=(actual_step/(actual_step+1))*p_mean.x.array[:] + 1/(actual_step+1)*p1.x.array[:]\n",
    "\n",
    "        u_fluct.x.array[:]=u1.x.array[:]-u_mean.x.array[:]\n",
    "\n",
    "        ####### Calcolo di f########\n",
    "        # voglio calcolare f, che risolta uguale a: f_prod= -dot(grad(u_fluct), u_fluct)\n",
    "        expr = dot(grad(u_fluct), u_fluct)\n",
    "        # Problema variazionale per la proiezione in V\n",
    "        u_f = fem.TrialFunction(V)\n",
    "        v_f = fem.TestFunction(V)\n",
    "        a_f = inner(u_f, v_f) * dx\n",
    "        L_f = inner(expr, v_f) * dx\n",
    "        # Risolvi la proiezione L2\n",
    "        problem = LinearProblem(a_f, L_f, bcs=[], petsc_options={\"ksp_type\": \"cg\"})\n",
    "        f_prod = -problem.solve()  # prod è una Function nello spazio V\n",
    "        \n",
    "        f.x.array[:]=(actual_step/(actual_step+1))*f_old.x.array[:] + 1/(actual_step+1)*f_prod.x.array[:]\n",
    "\n",
    "        #calcolo la differenza (norma) fra le variabili calcolate (mean_flow e forcing) in 2 iterazioni successive\n",
    "        # mi serve per poter verificare la convergenza  \n",
    "        err_mean = np.linalg.norm((u_mean_old.vector()[:] - u_mean.vector()[:])) / np.linalg.norm(u_mean_old.vector()[:])\n",
    "        err_forc = np.linalg.norm((f_old.vector()[:] - f.vector()[:])) / np.linalg.norm(f_old.vector()[:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if (err_mean < 1e-15 and err_forc < 1e-15) or step == step_final:\n",
    "            # cfl_max, dt_min = CFLnumber(domain, u1, dt)\n",
    "            '''Dobbiamo andare a calcolare il CFL number!!!!!!\n",
    "            Ma questa serà una cosa che vedrò una volta risolto il problema del crashing della simulazione!!!!!'''\n",
    "\n",
    "            MPI.COMM_WORLD.Barrier()\n",
    "\n",
    "            if step == step_final:\n",
    "                print(f'Last step reached: L2 mean:{err_mean}, L2 forc:{err_forc}')\n",
    "                #print(f\"Last step reached: L2 mean:{err_mean}, L2 forc:{err_forc}, CFL = {cfl_max}, dt = {dt_min}\")\n",
    "            else:\n",
    "                print(f'Convergence reached: L2 mean:{err_mean}, L2 forc:{err_forc}')\n",
    "                #print(f'Convergence reached: L2 mean:{err_mean}, L2 forc:{err_forc}, CFL = {cfl_max}, dt = {dt_min}')\n",
    "\n",
    "            MPI.COMM_WORLD.Barrier()\n",
    "            break\n",
    "\n",
    "        \n",
    "    if i in range(50,55):\n",
    "        print(f'STEP {i}')\n",
    "        print( f'u{i} = ', u1.x.array[:])\n",
    "        #print(f'Somma su u{i} = ',sum(u1.x.array[:]))\n",
    "        \n",
    "        print( f'p{i} = ', p1.x.array[:])\n",
    "        #print(f'Somma su p{i} = ',sum(p1.x.array[:]))\n",
    "        \n",
    "        print('')\n",
    "        \n",
    "    # Let's move to the next step!!!!!\n",
    "    # Update variable with solution form this time step\n",
    "    u0.x.array[:] = u1.x.array[:] # aggiorno il valore della u0 (che rappresenta u(n-1) nello step 1 dell'IPCS) \n",
    "    \n",
    "    f_old.x.array[:]=f.x.array[:] # aggiono il valore del forzaggio \n",
    "    p0.x.array[:] = p1.x.array[:] # aggiorno il valore della p0\n",
    "    \n",
    "    # Write solutions to file\n",
    "    vtx_u.write(t)\n",
    "    vtx_p.write(t)\n",
    "    \n",
    "    # # Compute error at current time-step\n",
    "    # error_L2 = np.sqrt(mesh.comm.allreduce(assemble_scalar(L2_error), op=MPI.SUM))\n",
    "    # error_max = mesh.comm.allreduce(np.max(u_.x.petsc_vec.array - u_ex.x.petsc_vec.array), op=MPI.MAX)\n",
    "    # # Print error only every 20th step and at the last step\n",
    "    # if (i % 20 == 0) or (i == num_steps - 1):\n",
    "    #     print(f\"Time {t:.2f}, L2-error {error_L2:.2e}, Max error {error_max:.2e}\")\n",
    "# Close xmdf file\n",
    "vtx_u.close()\n",
    "vtx_p.close()\n",
    "b1.destroy()\n",
    "b2.destroy()\n",
    "b3.destroy()\n",
    "solver1.destroy()\n",
    "solver2.destroy()\n",
    "solver3.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fenicsx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
